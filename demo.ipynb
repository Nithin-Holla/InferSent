{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Demo\n",
    "\n",
    "The following demo consists of two parts:\n",
    "1. User can input a premise and hypothesis and the prediction is displayed for the classifier models incorporating the following four encoders:\n",
    "    - BoW Baseline\n",
    "    - UniLSTM\n",
    "    - BiLSTM\n",
    "    - BiLSTM-MaxPool\n",
    "2. A list of sentences can be provided. The best-performing BiLSTM-MaxPool encoder is used to obtain their sentence embeddings. Next, a visualization of pairwise cosine similarity of the sentence embeddings is displayed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import torch\n",
    "import torchtext\n",
    "from SNLIClassifier import SNLIClassifier\n",
    "from nltk import word_tokenize\n",
    "import json\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to numericalize a sentence\n",
    "def numericalize(sentence, text_vocab, device):\n",
    "    sentence = word_tokenize(sentence)\n",
    "    sentence_len = torch.LongTensor(1).to(device)\n",
    "    sentence_len[0] = len(sentence)\n",
    "    numerical_sent = [text_vocab[word] if word in text_vocab else 0 for word in sentence]\n",
    "    numerical_sent = torch.tensor(numerical_sent).view(-1, 1).to(device)\n",
    "    return numerical_sent, sentence_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the model files and the vocab\n",
    "device = torch.device('cpu')\n",
    "model_path = 'checkpoint/'\n",
    "checkpoint_baseline = torch.load(model_path + 'average.pt', map_location=device)\n",
    "checkpoint_unilstm = torch.load(model_path + 'UniLSTM.pt', map_location=device)\n",
    "checkpoint_bilstm = torch.load(model_path + 'BiLSTM.pt', map_location=device)\n",
    "checkpoint_bilstm_max = torch.load(model_path + 'BiLSTMMaxPool.pt', map_location=device)\n",
    "text_vocab = checkpoint_baseline['text_vocab']\n",
    "label_vocab = checkpoint_baseline['label_vocab']\n",
    "vocab_size = len(text_vocab)\n",
    "label_mapping = sorted(label_vocab, key=label_vocab.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the models and loading the state_dict\n",
    "baseline_model = SNLIClassifier(encoder='average',\n",
    "                           vocab_size=vocab_size,\n",
    "                           embedding_dim=300,\n",
    "                           hidden_dim=2048,\n",
    "                           fc_dim=512,\n",
    "                           num_classes=3,\n",
    "                           pretrained_vectors=None)\n",
    "unilstm_model = SNLIClassifier(encoder='uniLSTM',\n",
    "                           vocab_size=vocab_size,\n",
    "                           embedding_dim=300,\n",
    "                           hidden_dim=2048,\n",
    "                           fc_dim=512,\n",
    "                           num_classes=3,\n",
    "                           pretrained_vectors=None)\n",
    "bilstm_model = SNLIClassifier(encoder='biLSTM',\n",
    "                           vocab_size=vocab_size,\n",
    "                           embedding_dim=300,\n",
    "                           hidden_dim=2048,\n",
    "                           fc_dim=512,\n",
    "                           num_classes=3,\n",
    "                           pretrained_vectors=None)\n",
    "bilstm_max_model = SNLIClassifier(encoder='biLSTMmaxpool',\n",
    "                           vocab_size=vocab_size,\n",
    "                           embedding_dim=300,\n",
    "                           hidden_dim=2048,\n",
    "                           fc_dim=512,\n",
    "                           num_classes=3,\n",
    "                           pretrained_vectors=None)\n",
    "\n",
    "baseline_model.load_state_dict(checkpoint_baseline['model_state_dict'])\n",
    "unilstm_model.load_state_dict(checkpoint_unilstm['model_state_dict'])\n",
    "bilstm_model.load_state_dict(checkpoint_bilstm['model_state_dict'])\n",
    "bilstm_max_model.load_state_dict(checkpoint_bilstm_max['model_state_dict'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 - Inference on user-input premise and hypothesis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter premise: The car was stuck in a traffic jam\n"
     ]
    }
   ],
   "source": [
    "# Premise input\n",
    "premise = input(\"Enter premise: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter hypothesis: The car was not stuck in a traffic jam\n"
     ]
    }
   ],
   "source": [
    "# Hypothesis input\n",
    "hypothesis = input(\"Enter hypothesis: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Numericalize premise and hypothesis\n",
    "premise, premise_len = numericalize(premise, text_vocab, device)\n",
    "hypothesis, hypothesis_len = numericalize(hypothesis, text_vocab, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline model prediction:  entailment\n"
     ]
    }
   ],
   "source": [
    "# Prediction from baseline model\n",
    "baseline_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = baseline_model(premise, hypothesis, premise_len, hypothesis_len)\n",
    "    prediction = torch.argmax(out, dim=1)\n",
    "print(\"Baseline model prediction: \", label_mapping[prediction])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UniLSTM model prediction:  contradiction\n"
     ]
    }
   ],
   "source": [
    "# Prediction from UniLSTM model\n",
    "unilstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = unilstm_model(premise, hypothesis, premise_len, hypothesis_len)\n",
    "    prediction = torch.argmax(out, dim=1)\n",
    "print(\"UniLSTM model prediction: \", label_mapping[prediction])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM model prediction:  contradiction\n"
     ]
    }
   ],
   "source": [
    "# Prediction from BiLSTM model\n",
    "bilstm_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = bilstm_model(premise, hypothesis, premise_len, hypothesis_len)\n",
    "    prediction = torch.argmax(out, dim=1)\n",
    "print(\"BiLSTM model prediction: \", label_mapping[prediction])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BiLSTM-MaxPool model prediction:  entailment\n"
     ]
    }
   ],
   "source": [
    "# Prediction from BiLSTM-MaxPool model\n",
    "bilstm_max_model.eval()\n",
    "with torch.no_grad():\n",
    "    out = bilstm_max_model(premise, hypothesis, premise_len, hypothesis_len)\n",
    "    prediction = torch.argmax(out, dim=1)\n",
    "print(\"BiLSTM-MaxPool model prediction: \", label_mapping[prediction])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Similarity of sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of input sentences\n",
    "sentence_list = ['It is raining today, hence I took an umbrella to work', \n",
    "                 'I had to take an umbrella because it was raining',\n",
    "                'Amsterdam attracts a large number of visitors',\n",
    "                'Amsterdam is visited by a large number of tourists',\n",
    "                'I like watching Game of Thrones',\n",
    "                'I dislike watching Game of Thrones',\n",
    "                'Artificial intelligence is the new electricity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain sentence embeddings\n",
    "bilstm_max_model.eval()\n",
    "sentence_embeddings = np.zeros((len(sentence_list), 2 * bilstm_max_model.hidden_dim))\n",
    "\n",
    "with torch.no_grad():\n",
    "    for idx, sentence in enumerate(sentence_list):\n",
    "        sent, sent_len = numericalize(sentence, text_vocab, device)\n",
    "        word_embedding = bilstm_max_model.embedding(sent)\n",
    "        sent_embedding = bilstm_max_model.encoder(word_embedding, sent_len)\n",
    "        sentence_embeddings[idx] = sent_embedding.numpy()  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pairwise sentence-similarity: \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute pairwise cosine distances and display as a heatmap\n",
    "cos_dist = cosine_similarity(sentence_embeddings, sentence_embeddings)\n",
    "print(\"Pairwise sentence cosine similarity: \")\n",
    "sns.heatmap(cos_dist);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
